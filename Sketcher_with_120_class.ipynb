{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketcher_with_120_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacd6ca4-bf11-4bba-fde8-bbf6dda8a8de"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 14:29:04--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt.1’\n",
            "\n",
            "\rmini_classes.txt.1    0%[                    ]       0  --.-KB/s               \rmini_classes.txt.1  100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-17 14:29:04 (52.4 MB/s) - ‘mini_classes.txt.1’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b"
      },
      "source": [
        "f = open(\"new_mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5"
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHzWNMCkKydA",
        "outputId": "1ca9a5f8-7b6c-4600-a95e-e514ec446c7a"
      },
      "source": [
        "print(len(classes))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ"
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a28f42-ba55-448c-c5b0-56e279698c68"
      },
      "source": [
        "download() "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bee.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camouflage.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crocodile.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dolphin.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dragon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/duck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elephant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/giraffe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mouse.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/owl.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pig.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zebra.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/whale.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl"
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3609d4-654f-4e63-b161-120ec1cec90d"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "384000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "529e3f55-2600-44c3-a9a8-915bcc41bcc7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "butterfly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4060e5bd-a075-40ea-ee65-e32627002d78"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(120, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 120)               15480     \n",
            "=================================================================\n",
            "Total params: 112,632\n",
            "Trainable params: 112,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc8a804-307f-43cd-ad18-8a1ac28c8ee7"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=50)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1350/1350 - 8s - loss: 1.0223 - top_k_categorical_accuracy: 0.9146 - val_loss: 1.0599 - val_top_k_categorical_accuracy: 0.9102\n",
            "Epoch 2/50\n",
            "1350/1350 - 7s - loss: 0.9846 - top_k_categorical_accuracy: 0.9185 - val_loss: 1.0447 - val_top_k_categorical_accuracy: 0.9121\n",
            "Epoch 3/50\n",
            "1350/1350 - 8s - loss: 0.9553 - top_k_categorical_accuracy: 0.9220 - val_loss: 1.0310 - val_top_k_categorical_accuracy: 0.9130\n",
            "Epoch 4/50\n",
            "1350/1350 - 7s - loss: 0.9305 - top_k_categorical_accuracy: 0.9246 - val_loss: 1.0173 - val_top_k_categorical_accuracy: 0.9159\n",
            "Epoch 5/50\n",
            "1350/1350 - 8s - loss: 0.9101 - top_k_categorical_accuracy: 0.9265 - val_loss: 1.0029 - val_top_k_categorical_accuracy: 0.9173\n",
            "Epoch 6/50\n",
            "1350/1350 - 7s - loss: 0.8905 - top_k_categorical_accuracy: 0.9287 - val_loss: 0.9971 - val_top_k_categorical_accuracy: 0.9175\n",
            "Epoch 7/50\n",
            "1350/1350 - 7s - loss: 0.8761 - top_k_categorical_accuracy: 0.9303 - val_loss: 0.9997 - val_top_k_categorical_accuracy: 0.9175\n",
            "Epoch 8/50\n",
            "1350/1350 - 7s - loss: 0.8618 - top_k_categorical_accuracy: 0.9317 - val_loss: 0.9896 - val_top_k_categorical_accuracy: 0.9185\n",
            "Epoch 9/50\n",
            "1350/1350 - 7s - loss: 0.8490 - top_k_categorical_accuracy: 0.9331 - val_loss: 0.9842 - val_top_k_categorical_accuracy: 0.9188\n",
            "Epoch 10/50\n",
            "1350/1350 - 7s - loss: 0.8372 - top_k_categorical_accuracy: 0.9340 - val_loss: 0.9743 - val_top_k_categorical_accuracy: 0.9212\n",
            "Epoch 11/50\n",
            "1350/1350 - 7s - loss: 0.8263 - top_k_categorical_accuracy: 0.9355 - val_loss: 0.9730 - val_top_k_categorical_accuracy: 0.9200\n",
            "Epoch 12/50\n",
            "1350/1350 - 7s - loss: 0.8185 - top_k_categorical_accuracy: 0.9360 - val_loss: 0.9754 - val_top_k_categorical_accuracy: 0.9205\n",
            "Epoch 13/50\n",
            "1350/1350 - 7s - loss: 0.8078 - top_k_categorical_accuracy: 0.9370 - val_loss: 0.9722 - val_top_k_categorical_accuracy: 0.9204\n",
            "Epoch 14/50\n",
            "1350/1350 - 7s - loss: 0.8004 - top_k_categorical_accuracy: 0.9382 - val_loss: 0.9746 - val_top_k_categorical_accuracy: 0.9196\n",
            "Epoch 15/50\n",
            "1350/1350 - 7s - loss: 0.7928 - top_k_categorical_accuracy: 0.9387 - val_loss: 0.9717 - val_top_k_categorical_accuracy: 0.9202\n",
            "Epoch 16/50\n",
            "1350/1350 - 7s - loss: 0.7855 - top_k_categorical_accuracy: 0.9396 - val_loss: 0.9732 - val_top_k_categorical_accuracy: 0.9209\n",
            "Epoch 17/50\n",
            "1350/1350 - 7s - loss: 0.7797 - top_k_categorical_accuracy: 0.9398 - val_loss: 0.9649 - val_top_k_categorical_accuracy: 0.9206\n",
            "Epoch 18/50\n",
            "1350/1350 - 7s - loss: 0.7728 - top_k_categorical_accuracy: 0.9404 - val_loss: 0.9745 - val_top_k_categorical_accuracy: 0.9208\n",
            "Epoch 19/50\n",
            "1350/1350 - 7s - loss: 0.7688 - top_k_categorical_accuracy: 0.9412 - val_loss: 0.9704 - val_top_k_categorical_accuracy: 0.9214\n",
            "Epoch 20/50\n",
            "1350/1350 - 7s - loss: 0.7632 - top_k_categorical_accuracy: 0.9419 - val_loss: 0.9883 - val_top_k_categorical_accuracy: 0.9187\n",
            "Epoch 21/50\n",
            "1350/1350 - 7s - loss: 0.7584 - top_k_categorical_accuracy: 0.9422 - val_loss: 0.9872 - val_top_k_categorical_accuracy: 0.9191\n",
            "Epoch 22/50\n",
            "1350/1350 - 7s - loss: 0.7546 - top_k_categorical_accuracy: 0.9425 - val_loss: 0.9819 - val_top_k_categorical_accuracy: 0.9195\n",
            "Epoch 23/50\n",
            "1350/1350 - 7s - loss: 0.7486 - top_k_categorical_accuracy: 0.9436 - val_loss: 0.9842 - val_top_k_categorical_accuracy: 0.9203\n",
            "Epoch 24/50\n",
            "1350/1350 - 7s - loss: 0.7446 - top_k_categorical_accuracy: 0.9435 - val_loss: 1.0000 - val_top_k_categorical_accuracy: 0.9189\n",
            "Epoch 25/50\n",
            "1350/1350 - 7s - loss: 0.7409 - top_k_categorical_accuracy: 0.9440 - val_loss: 0.9840 - val_top_k_categorical_accuracy: 0.9220\n",
            "Epoch 26/50\n",
            "1350/1350 - 7s - loss: 0.7365 - top_k_categorical_accuracy: 0.9444 - val_loss: 0.9748 - val_top_k_categorical_accuracy: 0.9208\n",
            "Epoch 27/50\n",
            "1350/1350 - 7s - loss: 0.7340 - top_k_categorical_accuracy: 0.9446 - val_loss: 0.9849 - val_top_k_categorical_accuracy: 0.9195\n",
            "Epoch 28/50\n",
            "1350/1350 - 7s - loss: 0.7291 - top_k_categorical_accuracy: 0.9451 - val_loss: 0.9835 - val_top_k_categorical_accuracy: 0.9203\n",
            "Epoch 29/50\n",
            "1350/1350 - 8s - loss: 0.7273 - top_k_categorical_accuracy: 0.9454 - val_loss: 0.9783 - val_top_k_categorical_accuracy: 0.9204\n",
            "Epoch 30/50\n",
            "1350/1350 - 7s - loss: 0.7235 - top_k_categorical_accuracy: 0.9458 - val_loss: 0.9878 - val_top_k_categorical_accuracy: 0.9198\n",
            "Epoch 31/50\n",
            "1350/1350 - 7s - loss: 0.7197 - top_k_categorical_accuracy: 0.9461 - val_loss: 1.0099 - val_top_k_categorical_accuracy: 0.9180\n",
            "Epoch 32/50\n",
            "1350/1350 - 8s - loss: 0.7176 - top_k_categorical_accuracy: 0.9464 - val_loss: 0.9877 - val_top_k_categorical_accuracy: 0.9196\n",
            "Epoch 33/50\n",
            "1350/1350 - 8s - loss: 0.7147 - top_k_categorical_accuracy: 0.9467 - val_loss: 0.9992 - val_top_k_categorical_accuracy: 0.9197\n",
            "Epoch 34/50\n",
            "1350/1350 - 7s - loss: 0.7117 - top_k_categorical_accuracy: 0.9471 - val_loss: 0.9879 - val_top_k_categorical_accuracy: 0.9206\n",
            "Epoch 35/50\n",
            "1350/1350 - 7s - loss: 0.7086 - top_k_categorical_accuracy: 0.9474 - val_loss: 1.0092 - val_top_k_categorical_accuracy: 0.9187\n",
            "Epoch 36/50\n",
            "1350/1350 - 7s - loss: 0.7076 - top_k_categorical_accuracy: 0.9474 - val_loss: 1.0018 - val_top_k_categorical_accuracy: 0.9193\n",
            "Epoch 37/50\n",
            "1350/1350 - 7s - loss: 0.7047 - top_k_categorical_accuracy: 0.9479 - val_loss: 1.0014 - val_top_k_categorical_accuracy: 0.9199\n",
            "Epoch 38/50\n",
            "1350/1350 - 7s - loss: 0.7020 - top_k_categorical_accuracy: 0.9481 - val_loss: 1.0075 - val_top_k_categorical_accuracy: 0.9185\n",
            "Epoch 39/50\n",
            "1350/1350 - 7s - loss: 0.6998 - top_k_categorical_accuracy: 0.9482 - val_loss: 1.0083 - val_top_k_categorical_accuracy: 0.9190\n",
            "Epoch 40/50\n",
            "1350/1350 - 8s - loss: 0.6974 - top_k_categorical_accuracy: 0.9485 - val_loss: 1.0014 - val_top_k_categorical_accuracy: 0.9199\n",
            "Epoch 41/50\n",
            "1350/1350 - 7s - loss: 0.6962 - top_k_categorical_accuracy: 0.9487 - val_loss: 1.0117 - val_top_k_categorical_accuracy: 0.9185\n",
            "Epoch 42/50\n",
            "1350/1350 - 7s - loss: 0.6946 - top_k_categorical_accuracy: 0.9490 - val_loss: 1.0024 - val_top_k_categorical_accuracy: 0.9193\n",
            "Epoch 43/50\n",
            "1350/1350 - 7s - loss: 0.6918 - top_k_categorical_accuracy: 0.9491 - val_loss: 1.0050 - val_top_k_categorical_accuracy: 0.9180\n",
            "Epoch 44/50\n",
            "1350/1350 - 7s - loss: 0.6893 - top_k_categorical_accuracy: 0.9492 - val_loss: 1.0092 - val_top_k_categorical_accuracy: 0.9199\n",
            "Epoch 45/50\n",
            "1350/1350 - 7s - loss: 0.6884 - top_k_categorical_accuracy: 0.9494 - val_loss: 1.0114 - val_top_k_categorical_accuracy: 0.9177\n",
            "Epoch 46/50\n",
            "1350/1350 - 7s - loss: 0.6856 - top_k_categorical_accuracy: 0.9498 - val_loss: 1.0112 - val_top_k_categorical_accuracy: 0.9180\n",
            "Epoch 47/50\n",
            "1350/1350 - 7s - loss: 0.6841 - top_k_categorical_accuracy: 0.9501 - val_loss: 1.0112 - val_top_k_categorical_accuracy: 0.9187\n",
            "Epoch 48/50\n",
            "1350/1350 - 7s - loss: 0.6828 - top_k_categorical_accuracy: 0.9497 - val_loss: 1.0118 - val_top_k_categorical_accuracy: 0.9194\n",
            "Epoch 49/50\n",
            "1350/1350 - 7s - loss: 0.6811 - top_k_categorical_accuracy: 0.9504 - val_loss: 1.0269 - val_top_k_categorical_accuracy: 0.9183\n",
            "Epoch 50/50\n",
            "1350/1350 - 7s - loss: 0.6793 - top_k_categorical_accuracy: 0.9504 - val_loss: 1.0286 - val_top_k_categorical_accuracy: 0.9184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f74b69fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13522704-9478-41f3-f34c-0b7a710e6ec2"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 91.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3JfoiYHdpk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "29f63745-8a4c-4316-c316-7fa1e58dacd4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['traffic_light', 'tennis_racquet', 'door', 'axe', 'broom']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN"
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce16a6b-4d88-439d-cf79-74e5ff4da0ed"
      },
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.10,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d871392-e44f-4e90-d6d0-cce7e1ae78d8"
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "2020-12-17 15:26:41.622493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63"
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46a937f-f494-4afb-8e27-d714d6a6bc4a"
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: model/ (stored 0%)\n",
            "updating: model/class_names.txt (deflated 42%)\n",
            "updating: model/model.json (deflated 82%)\n",
            "updating: model/group1-shard1of1.bin (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vfPR03xZZeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d29ff805-724f-4eba-aaed-6b54a861c84c"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e8635130-311f-4168-82d7-abf90e7128fb\", \"model.zip\", 421257)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYhYJpEKnpO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}